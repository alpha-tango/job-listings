{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "from os import listdir\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting similar job skills using word2vec\n",
    "We have a file with thousands of software engineer and similar job descriptions. We'd like to figure out from these job descriptions what job skills are related to each other. We'd like a job searcher with a given skill to be able to answer the questions:\n",
    "- What other skills are hiring managers looking for, in addition to the one that I have?\n",
    "- What kinds of jobs can I apply for? Are there job descriptions that say they want skill X, but the skill I have is a good enough substitute for that?\n",
    "\n",
    "Being able to answer these questions will help a candidate leverage their time building skills better, and apply to a wider range of jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation is in word2vec and divides the job descriptions into sentences based on \"lines\".\n",
    "The listings have had product and company names replaced with random letter strings, to anonymize them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '20180619.txt'\n",
    "with open(input_file, 'r') as f:\n",
    "    pre_vocabulary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_lists = []\n",
    "lines = pre_vocabulary.split(\"\\n\")\n",
    "for line in lines:\n",
    "    sentence_list = gensim.utils.simple_preprocess(line, deacc=False, min_len=2, max_len=30)\n",
    "    token_lists.append(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(token_lists, iter=10, min_count=1, size=300, workers=4)\n",
    "model.save('word2vec.model')\n",
    "vocab_size = len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scala', 0.7532507181167603),\n",
       " ('ag_zr_pd_js_av_og_rc_remote', 0.7324556112289429),\n",
       " ('perl', 0.7139312028884888),\n",
       " ('ruby', 0.6984028816223145),\n",
       " ('php', 0.6938693523406982),\n",
       " ('django', 0.6879407167434692),\n",
       " ('golang', 0.6731946468353271),\n",
       " ('clojure', 0.6319807767868042),\n",
       " ('nodejs', 0.6215530037879944),\n",
       " ('java', 0.6183958649635315)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_phrase = 'python'\n",
    "similar_vec = similar_phrase.split()\n",
    "model.wv.most_similar(positive=similar_vec, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is \"similar\" good enough?\n",
    "Word2vec comes up with mostly sensible results for \"similar\" skills, but it is only giving us skills that are _similar_. That could mean these skills are used similarly in job descriptions -- but it doesn't necessarily mean that a skill that counts as \"similar\" to the given one are always required together in the same job description, or that it could act as a substitute. So there are a few improvements we'd want to make -- we want to be able to tell\n",
    "- which skills are often asked for together (\"you must know skill X AND skill Y\")\n",
    "- which skills act as substitutes for eachother (\"you have experience with skill A OR skill B\")\n",
    "- whether a skill is a \"required\"/\"minimum qualification\" skill, or just a bonus (which we won't get to in this notebook).\n",
    "- whether the above is different based on seniority (which we also won't get to)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting skill combinations or substitutions\n",
    "\n",
    "#### Just parsing lines\n",
    "The simplest way to look for skills that asked for in combination is just to look for places in job descriptions that have `skill X` and `and` relatively close to each other. Same with skills that are substitutions -- we want `skill X` and `or` to be close to each other. Here, we can approximate that by looking for the two words (skill and connector) on the same line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_skill = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "and_lines = []\n",
    "or_lines = []\n",
    "\n",
    "for line in token_lists:\n",
    "    if key_skill in line and 'and' in line:\n",
    "        and_lines.append(line)\n",
    "    elif key_skill in line and 'or' in line:\n",
    "        or_lines.append(line)\n",
    "    else:\n",
    "       continue      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "development : 30 %\n",
      "java : 29 %\n",
      "software : 28 %\n",
      "javascript : 21 %\n",
      "languages : 19 %\n",
      "web : 19 %\n",
      "team : 18 %\n",
      "developer : 16 %\n",
      "django : 15 %\n",
      "programming : 15 %\n"
     ]
    }
   ],
   "source": [
    "and_lines_flattened = [item for sublist in and_lines for item in sublist]\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\",\n",
    "\"for\", \"if\", \"in\", \"into\", \"is\", \"it\",\n",
    "\"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"any\", \"other\", \"similar\",\n",
    "\"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"looking\", \"working\",\n",
    "\"they\", \"this\", \"to\", \"was\", \"will\", \"with\", \"we\", \"you\", \"our\", \"like\", \n",
    "              \"using\", \"from\", \"have\", \"work\", \"years\", \"experience\", key_skill]\n",
    "\n",
    "and_lines_flattened = [x for x in and_lines_flattened if x not in stop_words]\n",
    "\n",
    "from collections import Counter\n",
    "most_common = list(Counter(and_lines_flattened).most_common(10))\n",
    "for (i,x) in most_common:\n",
    "    print(i, ':', round(x * 100/len(and_lines)),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that the results also look reasonable, returning skills and general experience areas that look related. This helps answer the question,\"if I know X, what else do I need to know?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java : 42 %\n",
      "ruby : 30 %\n",
      "languages : 27 %\n",
      "perl : 24 %\n",
      "scripting : 21 %\n",
      "programming : 17 %\n",
      "one : 17 %\n",
      "language : 16 %\n",
      "php : 14 %\n",
      "javascript : 14 %\n"
     ]
    }
   ],
   "source": [
    "or_lines_flattened = [item for sublist in or_lines for item in sublist]\n",
    "or_lines_flattened = [x for x in or_lines_flattened if x not in stop_words]\n",
    "from collections import Counter\n",
    "Counter(or_lines_flattened).most_common(10)\n",
    "most_common = list(Counter(or_lines_flattened).most_common(10))\n",
    "for (i,x) in most_common:\n",
    "    print(i, ':', round(x * 100/len(or_lines)),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for this also look reasonable -- maybe a description for a job asks for Python but will accept Java or Ruby instead. We'd probably expect this to be the case more with junior positions than with senior ones, but we don't have a way of telling that at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Phrases and bigrams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Another way we can look for combinations / substitutions using `and` or `or` words is by using the gensim Phrases library and bigrams. This will tell us how frequently adjacent words occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_skill = 'rails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram = Phrases()\n",
    "bigram.add_vocab(token_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'rails_developer'   62\n",
      "b'rails_developers'  25\n",
      "b'rails_javascript'  20\n",
      "b'ruby_rails'        17\n",
      "b'rails_engineer'    17\n",
      "b'groovy_grails'     14\n",
      "b'rails_software'    12\n",
      "b'rails_development' 9\n",
      "b'rails_react'       8\n"
     ]
    }
   ],
   "source": [
    "bigram_counter = Counter()\n",
    "for key in bigram.vocab.keys():\n",
    "    split_key = str(key, 'utf-8').split(\"_\")\n",
    "    if len(split_key) > 1:\n",
    "        if str(split_key[0]) not in stop_words and str(split_key[1]) not in stop_words:\n",
    "            bigram_counter[key] += bigram.vocab[key]\n",
    "\n",
    "for key, counts in bigram_counter.most_common(10000):\n",
    "    if key_skill in str(key):\n",
    "        print('{0: <20} {1}'.format(str(key), counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to word2vec\n",
    "As another way of trying to detect clustered skills, I returned to word2vec. I started with a given skill, and scrubbed input lines mentioning that skill to just the few words before and after the skill, to try to tighten the similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_skill = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_lists_scrubbed = []\n",
    "n_words = 15\n",
    "idces = []\n",
    "\n",
    "linesx = pre_vocabulary.split(\"\\n\")\n",
    "for linex in linesx:\n",
    "    sentence_list_scrubbed = gensim.utils.simple_preprocess(linex, deacc=False, min_len=2, max_len=30)\n",
    "    try:\n",
    "        idx = sentence_list_scrubbed.index(key_skill)\n",
    "        idces.append(idx)\n",
    "        start_idx = max(0, idx - n_words)\n",
    "        end_idx = min(idx + n_words, len(sentence_list_scrubbed) - 1)\n",
    "        sentence_list_scrubbed = sentence_list_scrubbed[start_idx:end_idx]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    token_lists_scrubbed.append(sentence_list_scrubbed)\n",
    "    \n",
    "model2 = gensim.models.Word2Vec(token_lists_scrubbed, iter=10, min_count=1, size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('perl', 0.7397568225860596),\n",
       " ('scala', 0.7276171445846558),\n",
       " ('php', 0.7149808406829834),\n",
       " ('ruby', 0.7096331119537354),\n",
       " ('django', 0.7038027048110962),\n",
       " ('rails', 0.6401203274726868),\n",
       " ('golang', 0.6296257972717285),\n",
       " ('clojure', 0.6255342364311218),\n",
       " ('nodejs', 0.621862530708313),\n",
       " ('java', 0.6135293245315552)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar(positive=[key_skill], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to result in slightly more tools as opposed to general experience areas, which might make it more useful for a job seeker, but it loses the combination / substitution capacity of the above methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
